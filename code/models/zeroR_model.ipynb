{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load The Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd() \n",
    "relative_path = os.path.join('..','..', 'data', 'x_train.csv')\n",
    "x_train=pd.read_csv(os.path.join(current_dir, relative_path))\n",
    "relative_path = os.path.join('..','..', 'data', 'y_train.csv')\n",
    "y_train=pd.read_csv(os.path.join(current_dir, relative_path))\n",
    "\n",
    "relative_path = os.path.join('..','..', 'data', 'x_val.csv')\n",
    "x_val=pd.read_csv(os.path.join(current_dir, relative_path))\n",
    "relative_path = os.path.join('..','..', 'data', 'y_val.csv')\n",
    "y_val=pd.read_csv(os.path.join(current_dir, relative_path))\n",
    "\n",
    "relative_path = os.path.join('..','..', 'data', 'x_test.csv')\n",
    "x_test=pd.read_csv(os.path.join(current_dir, relative_path))\n",
    "relative_path = os.path.join('..','..', 'data', 'y_test.csv')\n",
    "y_test=pd.read_csv(os.path.join(current_dir, relative_path))\n",
    "\n",
    "relative_path = os.path.join('..','..', 'data', 'x_train_smote.csv')\n",
    "x_train_smote=pd.read_csv(os.path.join(current_dir, relative_path))\n",
    "relative_path = os.path.join('..','..', 'data', 'y_train_smote.csv')\n",
    "y_train_smote=pd.read_csv(os.path.join(current_dir, relative_path))\n",
    "\n",
    "relative_path = os.path.join('..','..', 'data', 'x_train_ros.csv')\n",
    "x_train_ros=pd.read_csv(os.path.join(current_dir, relative_path))\n",
    "relative_path = os.path.join('..','..', 'data', 'y_train_ros.csv')\n",
    "y_train_ros=pd.read_csv(os.path.join(current_dir, relative_path))\n",
    "\n",
    "relative_path = os.path.join('..','..', 'data', 'x_train_rur.csv')\n",
    "x_train_rur=pd.read_csv(os.path.join(current_dir, relative_path))\n",
    "relative_path = os.path.join('..','..', 'data', 'y_train_rur.csv')\n",
    "y_train_rur=pd.read_csv(os.path.join(current_dir, relative_path))\n",
    "\n",
    "relative_path = os.path.join('..','..', 'data', 'x_train_smotetomek.csv')\n",
    "x_train_smotetomek=pd.read_csv(os.path.join(current_dir, relative_path))\n",
    "relative_path = os.path.join('..','..', 'data', 'y_train_smotetomek.csv')\n",
    "y_train_smotetomek=pd.read_csv(os.path.join(current_dir, relative_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attrition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>882 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Attrition\n",
       "0            0\n",
       "1            0\n",
       "2            0\n",
       "3            0\n",
       "4            0\n",
       "..         ...\n",
       "877          0\n",
       "878          0\n",
       "879          0\n",
       "880          1\n",
       "881          1\n",
       "\n",
       "[882 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline model (zeroR)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=[\"Classifier\", \"Training Accuracy\", \"Validation Accuracy\", \"Testing Accuracy\", \"Training F1 Score\", \"Validation F1 Score\", \"Testing F1 Score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for ZeroR model:\n",
      "Accuracy on training data: 0.8372340425531914\n",
      "F1-score on training data: 0.7630610208330767\n",
      "Accuracy on validation data: 0.809322033898305\n",
      "F1-score on validation data: 0.7240304846584369\n",
      "Accuracy on test data: 0.8673469387755102\n",
      "F1-score on test data: 0.8057321289171407\n"
     ]
    }
   ],
   "source": [
    "majority_class = y_train['Attrition'].value_counts().idxmax()\n",
    "\n",
    "# Create and fit the ZeroR model\n",
    "zeroR_model = DummyClassifier(strategy='constant', constant=majority_class)\n",
    "zeroR_model.fit(x_train, y_train)\n",
    "\n",
    "# Predict using the ZeroR model\n",
    "y_pred_train = zeroR_model.predict(x_train)\n",
    "y_pred_val = zeroR_model.predict(x_val)\n",
    "y_pred_test = zeroR_model.predict(x_test)\n",
    "\n",
    "# Evaluate the performance of ZeroR\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "f1_val = f1_score(y_val, y_pred_val, average='weighted')\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "print(\"Metrics for ZeroR model:\")\n",
    "print(\"Accuracy on training data:\", accuracy_train)\n",
    "print(\"F1-score on training data:\", f1_train)\n",
    "print(\"Accuracy on validation data:\", accuracy_val)\n",
    "print(\"F1-score on validation data:\", f1_val)\n",
    "print(\"Accuracy on test data:\", accuracy_test)\n",
    "print(\"F1-score on test data:\", f1_test)\n",
    "\n",
    "# Create a temporary Series with results for this classifier\n",
    "temp_df = pd.DataFrame({\n",
    "    \"Classifier\": [\"without resampling\"], \n",
    "    \"Training Accuracy\": [accuracy_train], \n",
    "    \"Validation Accuracy\": [accuracy_val], \n",
    "    \"Testing Accuracy\": [accuracy_test], \n",
    "    \"Training F1 Score\": [f1_train], \n",
    "    \"Validation F1 Score\":[f1_val], \n",
    "    \"Testing F1 Score\":[f1_test]\n",
    "})\n",
    "\n",
    "# Append the Series as a new row to the results DataFrame\n",
    "results_df = pd.concat([results_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for ZeroR model:\n",
      "Accuracy on training data: 0.5\n",
      "F1-score on training data: 0.3333333333333333\n",
      "Accuracy on validation data: 0.809322033898305\n",
      "F1-score on validation data: 0.7240304846584369\n",
      "Accuracy on test data: 0.8673469387755102\n",
      "F1-score on test data: 0.8057321289171407\n"
     ]
    }
   ],
   "source": [
    "majority_class = y_train['Attrition'].value_counts().idxmax()\n",
    "\n",
    "# Create and fit the ZeroR model\n",
    "zeroR_model = DummyClassifier(strategy='constant', constant=majority_class)\n",
    "zeroR_model.fit(x_train_smote, y_train_smote)\n",
    "\n",
    "# Predict using the ZeroR model\n",
    "y_pred_train = zeroR_model.predict(x_train_smote)\n",
    "y_pred_val = zeroR_model.predict(x_val)\n",
    "y_pred_test = zeroR_model.predict(x_test)\n",
    "\n",
    "# Evaluate the performance of ZeroR\n",
    "accuracy_train = accuracy_score(y_train_smote, y_pred_train)\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "f1_train = f1_score(y_train_smote, y_pred_train, average='weighted')\n",
    "f1_val = f1_score(y_val, y_pred_val, average='weighted')\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "print(\"Metrics for ZeroR model:\")\n",
    "print(\"Accuracy on training data:\", accuracy_train)\n",
    "print(\"F1-score on training data:\", f1_train)\n",
    "print(\"Accuracy on validation data:\", accuracy_val)\n",
    "print(\"F1-score on validation data:\", f1_val)\n",
    "print(\"Accuracy on test data:\", accuracy_test)\n",
    "print(\"F1-score on test data:\", f1_test)\n",
    "\n",
    "# Create a temporary Series with results for this classifier\n",
    "temp_df = pd.DataFrame({\n",
    "    \"Classifier\": [\"SMOTE\"], \n",
    "    \"Training Accuracy\": [accuracy_train], \n",
    "    \"Validation Accuracy\": [accuracy_val], \n",
    "    \"Testing Accuracy\": [accuracy_test], \n",
    "    \"Training F1 Score\": [f1_train], \n",
    "    \"Validation F1 Score\":[f1_val], \n",
    "    \"Testing F1 Score\":[f1_test]\n",
    "})\n",
    "\n",
    "# Append the Series as a new row to the results DataFrame\n",
    "results_df = pd.concat([results_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for ZeroR model:\n",
      "Accuracy on training data: 0.5\n",
      "F1-score on training data: 0.3333333333333333\n",
      "Accuracy on validation data: 0.809322033898305\n",
      "F1-score on validation data: 0.7240304846584369\n",
      "Accuracy on test data: 0.8673469387755102\n",
      "F1-score on test data: 0.8057321289171407\n"
     ]
    }
   ],
   "source": [
    "majority_class = y_train['Attrition'].value_counts().idxmax()\n",
    "\n",
    "# Create and fit the ZeroR model\n",
    "zeroR_model = DummyClassifier(strategy='constant', constant=majority_class)\n",
    "zeroR_model.fit(x_train_ros, y_train_ros)\n",
    "\n",
    "# Predict using the ZeroR model\n",
    "y_pred_train = zeroR_model.predict(x_train_ros)\n",
    "y_pred_val = zeroR_model.predict(x_val)\n",
    "y_pred_test = zeroR_model.predict(x_test)\n",
    "\n",
    "# Evaluate the performance of ZeroR\n",
    "accuracy_train = accuracy_score(y_train_ros, y_pred_train)\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "f1_train = f1_score(y_train_ros, y_pred_train, average='weighted')\n",
    "f1_val = f1_score(y_val, y_pred_val, average='weighted')\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "print(\"Metrics for ZeroR model:\")\n",
    "print(\"Accuracy on training data:\", accuracy_train)\n",
    "print(\"F1-score on training data:\", f1_train)\n",
    "print(\"Accuracy on validation data:\", accuracy_val)\n",
    "print(\"F1-score on validation data:\", f1_val)\n",
    "print(\"Accuracy on test data:\", accuracy_test)\n",
    "print(\"F1-score on test data:\", f1_test)\n",
    "\n",
    "# Create a temporary Series with results for this classifier\n",
    "temp_df = pd.DataFrame({\n",
    "    \"Classifier\": [\"RandomOverSampler\"], \n",
    "    \"Training Accuracy\": [accuracy_train], \n",
    "    \"Validation Accuracy\": [accuracy_val], \n",
    "    \"Testing Accuracy\": [accuracy_test], \n",
    "    \"Training F1 Score\": [f1_train], \n",
    "    \"Validation F1 Score\":[f1_val], \n",
    "    \"Testing F1 Score\":[f1_test]\n",
    "})\n",
    "\n",
    "# Append the Series as a new row to the results DataFrame\n",
    "results_df = pd.concat([results_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for ZeroR model:\n",
      "Accuracy on training data: 0.5\n",
      "F1-score on training data: 0.3333333333333333\n",
      "Accuracy on validation data: 0.809322033898305\n",
      "F1-score on validation data: 0.7240304846584369\n",
      "Accuracy on test data: 0.8673469387755102\n",
      "F1-score on test data: 0.8057321289171407\n"
     ]
    }
   ],
   "source": [
    "majority_class = y_train['Attrition'].value_counts().idxmax()\n",
    "\n",
    "# Create and fit the ZeroR model\n",
    "zeroR_model = DummyClassifier(strategy='constant', constant=majority_class)\n",
    "zeroR_model.fit(x_train_smotetomek, y_train_smotetomek)\n",
    "\n",
    "# Predict using the ZeroR model\n",
    "y_pred_train = zeroR_model.predict(x_train_smotetomek)\n",
    "y_pred_val = zeroR_model.predict(x_val)\n",
    "y_pred_test = zeroR_model.predict(x_test)\n",
    "\n",
    "# Evaluate the performance of ZeroR\n",
    "accuracy_train = accuracy_score(y_train_smotetomek, y_pred_train)\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "f1_train = f1_score(y_train_smotetomek, y_pred_train, average='weighted')\n",
    "f1_val = f1_score(y_val, y_pred_val, average='weighted')\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "print(\"Metrics for ZeroR model:\")\n",
    "print(\"Accuracy on training data:\", accuracy_train)\n",
    "print(\"F1-score on training data:\", f1_train)\n",
    "print(\"Accuracy on validation data:\", accuracy_val)\n",
    "print(\"F1-score on validation data:\", f1_val)\n",
    "print(\"Accuracy on test data:\", accuracy_test)\n",
    "print(\"F1-score on test data:\", f1_test)\n",
    "\n",
    "# Create a temporary Series with results for this classifier\n",
    "temp_df = pd.DataFrame({\n",
    "    \"Classifier\": [\"SMOTETomek\"], \n",
    "    \"Training Accuracy\": [accuracy_train], \n",
    "    \"Validation Accuracy\": [accuracy_val], \n",
    "    \"Testing Accuracy\": [accuracy_test], \n",
    "    \"Training F1 Score\": [f1_train], \n",
    "    \"Validation F1 Score\":[f1_val], \n",
    "    \"Testing F1 Score\":[f1_test]\n",
    "})\n",
    "\n",
    "# Append the Series as a new row to the results DataFrame\n",
    "results_df = pd.concat([results_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for ZeroR model:\n",
      "Accuracy on training data: 0.5\n",
      "weighted F1-score on training data: 0.3333333333333333\n",
      "Accuracy on validation data: 0.809322033898305\n",
      "weighted F1-score on validation data: 0.7240304846584369\n",
      "Accuracy on test data: 0.8673469387755102\n",
      "weighted F1-score on test data: 0.8057321289171407\n"
     ]
    }
   ],
   "source": [
    "majority_class = y_train['Attrition'].value_counts().idxmax()\n",
    "\n",
    "# Create and fit the ZeroR model\n",
    "zeroR_model = DummyClassifier(strategy='constant', constant=majority_class)\n",
    "zeroR_model.fit(x_train_rur, y_train_rur)\n",
    "\n",
    "# Predict using the ZeroR model\n",
    "y_pred_train = zeroR_model.predict(x_train_rur)\n",
    "y_pred_val = zeroR_model.predict(x_val)\n",
    "y_pred_test = zeroR_model.predict(x_test)\n",
    "\n",
    "# Evaluate the performance of ZeroR\n",
    "accuracy_train = accuracy_score(y_train_rur, y_pred_train)\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "f1_train = f1_score(y_train_rur, y_pred_train, average='weighted')\n",
    "f1_val = f1_score(y_val, y_pred_val, average='weighted')\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "print(\"Metrics for ZeroR model:\")\n",
    "print(\"Accuracy on training data:\", accuracy_train)\n",
    "print(\"weighted F1-score on training data:\", f1_train)\n",
    "print(\"Accuracy on validation data:\", accuracy_val)\n",
    "print(\"weighted F1-score on validation data:\", f1_val)\n",
    "print(\"Accuracy on test data:\", accuracy_test)\n",
    "print(\"weighted F1-score on test data:\", f1_test)\n",
    "\n",
    "# Create a temporary Series with results for this classifier\n",
    "temp_df = pd.DataFrame({\n",
    "    \"Classifier\": [\"RandomUnderSampler\"], \n",
    "    \"Training Accuracy\": [accuracy_train], \n",
    "    \"Validation Accuracy\": [accuracy_val], \n",
    "    \"Testing Accuracy\": [accuracy_test], \n",
    "    \"Training F1 Score\": [f1_train], \n",
    "    \"Validation F1 Score\":[f1_val], \n",
    "    \"Testing F1 Score\":[f1_test]\n",
    "})\n",
    "\n",
    "# Append the Series as a new row to the results DataFrame\n",
    "results_df = pd.concat([results_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Training F1 Score</th>\n",
       "      <th>Validation F1 Score</th>\n",
       "      <th>Testing F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>without resampling</td>\n",
       "      <td>0.837234</td>\n",
       "      <td>0.809322</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.763061</td>\n",
       "      <td>0.72403</td>\n",
       "      <td>0.805732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.809322</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.72403</td>\n",
       "      <td>0.805732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.809322</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.72403</td>\n",
       "      <td>0.805732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.809322</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.72403</td>\n",
       "      <td>0.805732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.809322</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.72403</td>\n",
       "      <td>0.805732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Classifier  Training Accuracy  Validation Accuracy  \\\n",
       "0  without resampling           0.837234             0.809322   \n",
       "1               SMOTE           0.500000             0.809322   \n",
       "2   RandomOverSampler           0.500000             0.809322   \n",
       "3          SMOTETomek           0.500000             0.809322   \n",
       "4  RandomUnderSampler           0.500000             0.809322   \n",
       "\n",
       "   Testing Accuracy  Training F1 Score  Validation F1 Score  Testing F1 Score  \n",
       "0          0.867347           0.763061              0.72403          0.805732  \n",
       "1          0.867347           0.333333              0.72403          0.805732  \n",
       "2          0.867347           0.333333              0.72403          0.805732  \n",
       "3          0.867347           0.333333              0.72403          0.805732  \n",
       "4          0.867347           0.333333              0.72403          0.805732  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (geospatial)",
   "language": "python",
   "name": "geospatial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
