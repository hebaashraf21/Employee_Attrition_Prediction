{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "#!pip install catboost\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import KFold\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Loading The Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd() \n",
        "relative_path = os.path.join('..', '..','data', 'train.csv')\n",
        "train_data = pd.read_csv(os.path.join(current_dir, relative_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "relative_path = os.path.join('..', '..','data', 'test.csv')\n",
        "test_data = pd.read_csv(os.path.join(current_dir, relative_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "x_train = train_data.drop([\"Attrition\"], axis = 1)\n",
        "y_train = train_data[\"Attrition\"]\n",
        "\n",
        "x_test = test_data.drop([\"Attrition\"], axis = 1)\n",
        "y_test = test_data[\"Attrition\"]\n",
        "\n",
        "k_fold = KFold(n_splits=10, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Trying Different Class Weights**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For Class Weights : [1, 1]\n",
            "Average Accuracy: 0.8704597701149426\n",
            "Average F1 Score: 0.04\n",
            "Average Precision: 0.1\n",
            "Average Recall: 0.025\n",
            "-----------------------------------------------------\n",
            "For Class Weights : [1, 5]\n",
            "Average Accuracy: 0.8437931034482758\n",
            "Average F1 Score: 0.40715728715728716\n",
            "Average Precision: 0.4419047619047619\n",
            "Average Recall: 0.44416666666666665\n",
            "-----------------------------------------------------\n",
            "For Class Weights : [1, 10]\n",
            "Average Accuracy: 0.793103448275862\n",
            "Average F1 Score: 0.5559499082900619\n",
            "Average Precision: 0.4786538461538462\n",
            "Average Recall: 0.8633333333333333\n",
            "-----------------------------------------------------\n",
            "For Class Weights : [1, 15]\n",
            "Average Accuracy: 0.6836781609195403\n",
            "Average F1 Score: 0.5201533538146442\n",
            "Average Precision: 0.419845372019285\n",
            "Average Recall: 0.9291666666666666\n",
            "-----------------------------------------------------\n",
            "For Class Weights : [1, 20]\n",
            "Average Accuracy: 0.6757471264367816\n",
            "Average F1 Score: 0.48895497827439743\n",
            "Average Precision: 0.37577540106951873\n",
            "Average Recall: 0.9291666666666666\n",
            "-----------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "class_weights = [[1,1], [1,5], [1,10], [1,15], [1,20]]\n",
        "for class_weight in class_weights:\n",
        "    # Define CatBoost parameters\n",
        "    params = {\n",
        "        'learning_rate': 0.1,               # Learning Rate\n",
        "        'n_estimators': 100,                # Number of Trees\n",
        "        'max_depth': 6,                     # Depth of Trees\n",
        "        'l2_leaf_reg': 3,                   # Regularization Parameter: L2 regularization\n",
        "        'min_child_samples': 5,             # Regularization Parameter: Minimum number of samples required to split a node\n",
        "        'subsample': 0.8,                   # Subsampling\n",
        "        'loss_function': 'Logloss',         # Objective Function\n",
        "        'eval_metric': 'Accuracy',                # Evaluation Metric\n",
        "        'border_count': 128,                 # Gradient Estimation\n",
        "        'class_weights': class_weight  # Adjust class weights because of unbalanced classes\n",
        "    }\n",
        "\n",
        "    # Initialize CatBoost classifier\n",
        "    catboost_model = CatBoostClassifier(**params)\n",
        "\n",
        "    # Train the model using KFold cross-validation\n",
        "    accuracies = []\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for train_index, val_index in k_fold.split(x_train):\n",
        "        X_train_fold, X_val_fold = x_train.iloc[train_index], x_train.iloc[val_index]\n",
        "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "        \n",
        "        # Fit the model\n",
        "        catboost_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False)\n",
        "        \n",
        "        # Predict on validation set\n",
        "        y_pred = catboost_model.predict(X_val_fold)\n",
        "        \n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_val_fold, y_pred)\n",
        "        precision = precision_score(y_val_fold, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_val_fold, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_val_fold, y_pred, zero_division=0)\n",
        "        \n",
        "        accuracies.append(accuracy)\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    # Calculate and print average metrics\n",
        "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
        "    avg_precision = sum(precisions) / len(precisions)\n",
        "    avg_recall = sum(recalls) / len(recalls)\n",
        "    avg_f1_score = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "    print(\"For Class Weights :\", class_weight)\n",
        "    print(\"Average Accuracy:\", avg_accuracy)\n",
        "    print(\"Average F1 Score:\", avg_f1_score)\n",
        "    print(\"Average Precision:\", avg_precision)\n",
        "    print(\"Average Recall:\", avg_recall)\n",
        "    print('-----------------------------------------------------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Trying Different Learning Rates**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For learning rate : 0.01\n",
            "Average Accuracy: 0.747816091954023\n",
            "Average F1 Score: 0.47449381536338053\n",
            "Average Precision: 0.35378193701723115\n",
            "Average Recall: 0.8383333333333333\n",
            "Average Training Time (seconds): 0.5286627292633057\n",
            "-----------------------------------------------------\n",
            "For learning rate : 0.05\n",
            "Average Accuracy: 0.7766666666666666\n",
            "Average F1 Score: 0.5323148178902655\n",
            "Average Precision: 0.43923243423243424\n",
            "Average Recall: 0.8633333333333333\n",
            "Average Training Time (seconds): 0.4467919826507568\n",
            "-----------------------------------------------------\n",
            "For learning rate : 0.1\n",
            "Average Accuracy: 0.793103448275862\n",
            "Average F1 Score: 0.5559499082900619\n",
            "Average Precision: 0.4786538461538462\n",
            "Average Recall: 0.8633333333333333\n",
            "Average Training Time (seconds): 0.44788100719451907\n",
            "-----------------------------------------------------\n",
            "For learning rate : 0.3\n",
            "Average Accuracy: 0.7562068965517241\n",
            "Average F1 Score: 0.41913838647853996\n",
            "Average Precision: 0.3427790346907994\n",
            "Average Recall: 0.6983333333333335\n",
            "Average Training Time (seconds): 0.464043927192688\n",
            "-----------------------------------------------------\n",
            "For learning rate : 0.5\n",
            "Average Accuracy: 0.7164367816091953\n",
            "Average F1 Score: 0.44377921950172594\n",
            "Average Precision: 0.3470054945054945\n",
            "Average Recall: 0.8183333333333334\n",
            "Average Training Tgit config pull.rebase falseime (seconds): 0.4365460634231567\n",
            "-----------------------------------------------------\n",
            "For learning rate : 0.7\n",
            "Average Accuracy: 0.7549425287356322\n",
            "Average F1 Score: 0.44848959082974427\n",
            "Average Precision: 0.37190559440559434\n",
            "Average Recall: 0.7783333333333334\n",
            "Average Training Time (seconds): 0.4948091745376587\n",
            "-----------------------------------------------------\n",
            "For learning rate : 0.9\n",
            "Average Accuracy: 0.6517241379310346\n",
            "Average F1 Score: 0.37156410890426234\n",
            "Average Precision: 0.27005183222574525\n",
            "Average Recall: 0.8116666666666668\n",
            "Average Training Time (seconds): 0.5446034908294678\n",
            "-----------------------------------------------------\n",
            "For learning rate : 1\n",
            "Average Accuracy: 0.7351724137931034\n",
            "Average F1 Score: 0.4277294685990339\n",
            "Average Precision: 0.34429487179487184\n",
            "Average Recall: 0.7616666666666666\n",
            "Average Training Time (seconds): 0.47791030406951907\n",
            "-----------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "learning_rates = [0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 0.9, 1]\n",
        "for lr in learning_rates:\n",
        "    # Define CatBoost parameters\n",
        "    params = {\n",
        "        'learning_rate': lr,               # Learning Rate\n",
        "        'n_estimators': 100,                # Number of Trees\n",
        "        'max_depth': 6,                     # Depth of Trees\n",
        "        'l2_leaf_reg': 3,                   # Regularization Parameter: L2 regularization\n",
        "        'min_child_samples': 5,             # Regularization Parameter: Minimum number of samples required to split a node\n",
        "        'subsample': 0.8,                   # Subsampling\n",
        "        'loss_function': 'Logloss',         # Objective Function\n",
        "        'eval_metric': 'Accuracy',                # Evaluation Metric\n",
        "        'border_count': 128,                 # Gradient Estimation\n",
        "        'class_weights': [1, 10]  # Adjust class weights because of unbalanced classes\n",
        "    }\n",
        "\n",
        "    # Initialize CatBoost classifier\n",
        "    catboost_model = CatBoostClassifier(**params)\n",
        "\n",
        "    # Train the model using KFold cross-validation\n",
        "    accuracies = []\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1_scores = []\n",
        "    training_times = []\n",
        "\n",
        "    for train_index, val_index in k_fold.split(x_train):\n",
        "        X_train_fold, X_val_fold = x_train.iloc[train_index], x_train.iloc[val_index]\n",
        "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "        \n",
        "        # Record start time\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Fit the model\n",
        "        catboost_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False)\n",
        "        \n",
        "        # Record end time\n",
        "        end_time = time.time()\n",
        "        \n",
        "        # Calculate training time\n",
        "        training_time = end_time - start_time\n",
        "        training_times.append(training_time)\n",
        "        \n",
        "        # Predict on validation set\n",
        "        y_pred = catboost_model.predict(X_val_fold)\n",
        "        \n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_val_fold, y_pred)\n",
        "        precision = precision_score(y_val_fold, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_val_fold, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_val_fold, y_pred, zero_division=0)\n",
        "        \n",
        "        accuracies.append(accuracy)\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    # Calculate and print average metrics\n",
        "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
        "    avg_precision = sum(precisions) / len(precisions)\n",
        "    avg_recall = sum(recalls) / len(recalls)\n",
        "    avg_f1_score = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "    # Calculate average training time\n",
        "    avg_training_time = sum(training_times) / len(training_times)\n",
        "    print(\"For learning rate :\", lr)\n",
        "    print(\"Average Accuracy:\", avg_accuracy)\n",
        "    print(\"Average F1 Score:\", avg_f1_score)\n",
        "    print(\"Average Precision:\", avg_precision)\n",
        "    print(\"Average Recall:\", avg_recall)\n",
        "    print(\"Average Training Time (seconds):\", avg_training_time)\n",
        "    print('-----------------------------------------------------')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Trying different combinations between learning rates and class weights**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best F1 Score: 0.5559499082900619\n",
            "Corresponding Accuracy: 0.793103448275862\n",
            "Corresponding Learning Rate: 0.1\n",
            "Corresponding Class Weight: [1, 10]\n"
          ]
        }
      ],
      "source": [
        "learning_rates = [0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 0.9, 1]\n",
        "class_weights = [[1,1], [1,5], [1,10], [1,15], [1,20]]\n",
        "\n",
        "max_f1_score = 0\n",
        "best_accuracy = 0\n",
        "best_lr = None\n",
        "best_class_weight = None\n",
        "\n",
        "for class_weight in class_weights:\n",
        "    for lr in learning_rates:\n",
        "        # Define CatBoost parameters\n",
        "        params = {\n",
        "            'learning_rate': lr,               # Learning Rate\n",
        "            'n_estimators': 100,                # Number of Trees\n",
        "            'max_depth': 6,                     # Depth of Trees\n",
        "            'l2_leaf_reg': 3,                   # Regularization Parameter: L2 regularization\n",
        "            'min_child_samples': 5,             # Regularization Parameter: Minimum number of samples required to split a node\n",
        "            'subsample': 0.8,                   # Subsampling\n",
        "            'loss_function': 'Logloss',         # Objective Function\n",
        "            'eval_metric': 'Accuracy',                # Evaluation Metric\n",
        "            'border_count': 128,                 # Gradient Estimation\n",
        "            'class_weights': class_weight  # Adjust class weights because of unbalanced classes\n",
        "        }\n",
        "        # Initialize CatBoost classifier\n",
        "        catboost_model = CatBoostClassifier(**params)\n",
        "\n",
        "        # Train the model using KFold cross-validation\n",
        "        accuracies = []\n",
        "        precisions = []\n",
        "        recalls = []\n",
        "        f1_scores = []\n",
        "        training_times = []\n",
        "\n",
        "        for train_index, val_index in k_fold.split(x_train):\n",
        "            X_train_fold, X_val_fold = x_train.iloc[train_index], x_train.iloc[val_index]\n",
        "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "            \n",
        "            # Record start time\n",
        "            start_time = time.time()\n",
        "            \n",
        "            # Fit the model\n",
        "            catboost_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False)\n",
        "            \n",
        "            # Record end time\n",
        "            end_time = time.time()\n",
        "            \n",
        "            # Calculate training time\n",
        "            training_time = end_time - start_time\n",
        "            training_times.append(training_time)\n",
        "            \n",
        "            # Predict on validation set\n",
        "            y_pred = catboost_model.predict(X_val_fold)\n",
        "            \n",
        "            # Calculate metrics\n",
        "            accuracy = accuracy_score(y_val_fold, y_pred)\n",
        "            precision = precision_score(y_val_fold, y_pred, zero_division=0)\n",
        "            recall = recall_score(y_val_fold, y_pred, zero_division=0)\n",
        "            f1 = f1_score(y_val_fold, y_pred, zero_division=0)\n",
        "            \n",
        "            accuracies.append(accuracy)\n",
        "            precisions.append(precision)\n",
        "            recalls.append(recall)\n",
        "            f1_scores.append(f1)\n",
        "\n",
        "        # Calculate and print average metrics\n",
        "        avg_accuracy = sum(accuracies) / len(accuracies)\n",
        "        avg_precision = sum(precisions) / len(precisions)\n",
        "        avg_recall = sum(recalls) / len(recalls)\n",
        "        avg_f1_score = sum(f1_scores) / len(f1_scores)\n",
        "        \n",
        "        if avg_f1_score > max_f1_score:\n",
        "            max_f1_score = avg_f1_score\n",
        "            best_accuracy = avg_accuracy\n",
        "            best_lr = lr\n",
        "            best_class_weight = class_weight\n",
        "\n",
        "# Print the results for the best F1 score\n",
        "print(\"Best F1 Score:\", max_f1_score)\n",
        "print(\"Corresponding Accuracy:\", best_accuracy)\n",
        "print(\"Corresponding Learning Rate:\", best_lr)\n",
        "print(\"Corresponding Class Weight:\", best_class_weight)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Trying Different Number Of Trees (n_estimators)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For n_estimators : 50\n",
            "Average Accuracy: 0.7896551724137931\n",
            "Average F1 Score: 0.5426165749567284\n",
            "Average Precision: 0.4453205128205129\n",
            "Average Recall: 0.8633333333333333\n",
            "Average Training Time (seconds): 0.43857033252716066\n",
            "-----------------------------------------------------\n",
            "For n_estimators : 100\n",
            "Average Accuracy: 0.793103448275862\n",
            "Average F1 Score: 0.5559499082900619\n",
            "Average Precision: 0.4786538461538462\n",
            "Average Recall: 0.8633333333333333\n",
            "Average Training Time (seconds): 0.5430788516998291\n",
            "-----------------------------------------------------\n",
            "For n_estimators : 200\n",
            "Average Accuracy: 0.793103448275862\n",
            "Average F1 Score: 0.5559499082900619\n",
            "Average Precision: 0.4786538461538462\n",
            "Average Recall: 0.8633333333333333\n",
            "Average Training Time (seconds): 0.7377847909927369\n",
            "-----------------------------------------------------\n",
            "For n_estimators : 300\n",
            "Average Accuracy: 0.793103448275862\n",
            "Average F1 Score: 0.5559499082900619\n",
            "Average Precision: 0.4786538461538462\n",
            "Average Recall: 0.8633333333333333\n",
            "Average Training Time (seconds): 0.9774594783782959\n",
            "-----------------------------------------------------\n",
            "For n_estimators : 500\n",
            "Average Accuracy: 0.793103448275862\n",
            "Average F1 Score: 0.5559499082900619\n",
            "Average Precision: 0.4786538461538462\n",
            "Average Recall: 0.8633333333333333\n",
            "Average Training Time (seconds): 1.382635807991028\n",
            "-----------------------------------------------------\n",
            "For n_estimators : 800\n",
            "Average Accuracy: 0.793103448275862\n",
            "Average F1 Score: 0.5559499082900619\n",
            "Average Precision: 0.4786538461538462\n",
            "Average Recall: 0.8633333333333333\n",
            "Average Training Time (seconds): 2.238626170158386\n",
            "-----------------------------------------------------\n",
            "For n_estimators : 1000\n",
            "Average Accuracy: 0.793103448275862\n",
            "Average F1 Score: 0.5559499082900619\n",
            "Average Precision: 0.4786538461538462\n",
            "Average Recall: 0.8633333333333333\n",
            "Average Training Time (seconds): 2.367002534866333\n",
            "-----------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "n_estimators_list = [50, 100, 200, 300, 500, 800, 1000]\n",
        "for n_estimators in n_estimators_list:\n",
        "    # Define CatBoost parameters\n",
        "    params = {\n",
        "        'learning_rate': 0.1,               # Learning Rate\n",
        "        'n_estimators': n_estimators,                # Number of Trees\n",
        "        'max_depth': 6,                     # Depth of Trees\n",
        "        'l2_leaf_reg': 3,                   # Regularization Parameter: L2 regularization\n",
        "        'min_child_samples': 5,             # Regularization Parameter: Minimum number of samples required to split a node\n",
        "        'subsample': 0.8,                   # Subsampling\n",
        "        'loss_function': 'Logloss',         # Objective Function\n",
        "        'eval_metric': 'Accuracy',                # Evaluation Metric\n",
        "        'border_count': 128,                 # Gradient Estimation\n",
        "        'class_weights': [1, 10]  # Adjust class weights because of unbalanced classes\n",
        "    }\n",
        "\n",
        "    # Initialize CatBoost classifier\n",
        "    catboost_model = CatBoostClassifier(**params)\n",
        "\n",
        "    # Train the model using KFold cross-validation\n",
        "    accuracies = []\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1_scores = []\n",
        "    training_times = []\n",
        "\n",
        "    for train_index, val_index in k_fold.split(x_train):\n",
        "        X_train_fold, X_val_fold = x_train.iloc[train_index], x_train.iloc[val_index]\n",
        "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "        \n",
        "        # Record start time\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Fit the model\n",
        "        catboost_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False)\n",
        "        \n",
        "        # Record end time\n",
        "        end_time = time.time()\n",
        "        \n",
        "        # Calculate training time\n",
        "        training_time = end_time - start_time\n",
        "        training_times.append(training_time)\n",
        "        \n",
        "        # Predict on validation set\n",
        "        y_pred = catboost_model.predict(X_val_fold)\n",
        "        \n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_val_fold, y_pred)\n",
        "        precision = precision_score(y_val_fold, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_val_fold, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_val_fold, y_pred, zero_division=0)\n",
        "        \n",
        "        accuracies.append(accuracy)\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    # Calculate and print average metrics\n",
        "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
        "    avg_precision = sum(precisions) / len(precisions)\n",
        "    avg_recall = sum(recalls) / len(recalls)\n",
        "    avg_f1_score = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "    # Calculate average training time\n",
        "    avg_training_time = sum(training_times) / len(training_times)\n",
        "    print(\"For n_estimators :\", n_estimators)\n",
        "    print(\"Average Accuracy:\", avg_accuracy)\n",
        "    print(\"Average F1 Score:\", avg_f1_score)\n",
        "    print(\"Average Precision:\", avg_precision)\n",
        "    print(\"Average Recall:\", avg_recall)\n",
        "    print(\"Average Training Time (seconds):\", avg_training_time)\n",
        "    print('-----------------------------------------------------')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Trying Different Trees Depth (max_depth)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For max_depth : 2\n",
            "Average Accuracy: 0.6354022988505748\n",
            "Average F1 Score: 0.4242309708013776\n",
            "Average Precision: 0.2924515979189892\n",
            "Average Recall: 0.9425000000000001\n",
            "Average Training Time (seconds): 0.46471168994903567\n",
            "-----------------------------------------------------\n",
            "For max_depth : 4\n",
            "Average Accuracy: 0.7417241379310345\n",
            "Average F1 Score: 0.4778112670446767\n",
            "Average Precision: 0.3663798701298701\n",
            "Average Recall: 0.8675\n",
            "Average Training Time (seconds): 0.4825791597366333\n",
            "-----------------------------------------------------\n",
            "For max_depth : 6\n",
            "Average Accuracy: 0.793103448275862\n",
            "Average F1 Score: 0.5559499082900619\n",
            "Average Precision: 0.4786538461538462\n",
            "Average Recall: 0.8633333333333333\n",
            "Average Training Time (seconds): 0.5299882888793945\n",
            "-----------------------------------------------------\n",
            "For max_depth : 8\n",
            "Average Accuracy: 0.7282758620689654\n",
            "Average F1 Score: 0.43453954456276433\n",
            "Average Precision: 0.34593137254901957\n",
            "Average Recall: 0.7424999999999999\n",
            "Average Training Time (seconds): 0.7479905128479004\n",
            "-----------------------------------------------------\n",
            "For max_depth : 10\n",
            "Average Accuracy: 0.8402298850574713\n",
            "Average F1 Score: 0.42683982683982674\n",
            "Average Precision: 0.4033333333333333\n",
            "Average Recall: 0.5608333333333333\n",
            "Average Training Time (seconds): 1.2559390544891358\n",
            "-----------------------------------------------------\n",
            "For max_depth : 12\n",
            "Average Accuracy: 0.810344827586207\n",
            "Average F1 Score: 0.49093795093795095\n",
            "Average Precision: 0.5520238095238095\n",
            "Average Recall: 0.6258333333333334\n",
            "Average Training Time (seconds): 3.2754815101623533\n",
            "-----------------------------------------------------\n",
            "For max_depth : 14\n",
            "Average Accuracy: 0.7933333333333333\n",
            "Average F1 Score: 0.4493722943722943\n",
            "Average Precision: 0.45117549117549105\n",
            "Average Recall: 0.6925\n",
            "Average Training Time (seconds): 9.26327428817749\n",
            "-----------------------------------------------------\n",
            "For max_depth : 16\n",
            "Average Accuracy: 0.7657471264367816\n",
            "Average F1 Score: 0.3909808165690519\n",
            "Average Precision: 0.45576976944624\n",
            "Average Recall: 0.6041666666666667\n",
            "Average Training Time (seconds): 32.898765969276425\n",
            "-----------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "max_depth_list = [2, 4, 6, 8, 10, 12, 14, 16]\n",
        "for max_depth in max_depth_list:\n",
        "    # Define CatBoost parameters\n",
        "    params = {\n",
        "        'learning_rate': 0.1,               # Learning Rate\n",
        "        'n_estimators': 100,                # Number of Trees\n",
        "        'max_depth': max_depth,                     # Depth of Trees\n",
        "        'l2_leaf_reg': 3,                   # Regularization Parameter: L2 regularization\n",
        "        'min_child_samples': 5,             # Regularization Parameter: Minimum number of samples required to split a node\n",
        "        'subsample': 0.8,                   # Subsampling\n",
        "        'loss_function': 'Logloss',         # Objective Function\n",
        "        'eval_metric': 'Accuracy',                # Evaluation Metric\n",
        "        'border_count': 128,                 # Gradient Estimation\n",
        "        'class_weights': [1, 10]  # Adjust class weights because of unbalanced classes\n",
        "    }\n",
        "\n",
        "    # Initialize CatBoost classifier\n",
        "    catboost_model = CatBoostClassifier(**params)\n",
        "\n",
        "    # Train the model using KFold cross-validation\n",
        "    accuracies = []\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1_scores = []\n",
        "    training_times = []\n",
        "\n",
        "    for train_index, val_index in k_fold.split(x_train):\n",
        "        X_train_fold, X_val_fold = x_train.iloc[train_index], x_train.iloc[val_index]\n",
        "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "        \n",
        "        # Record start time\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Fit the model\n",
        "        catboost_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False)\n",
        "        \n",
        "        # Record end time\n",
        "        end_time = time.time()\n",
        "        \n",
        "        # Calculate training time\n",
        "        training_time = end_time - start_time\n",
        "        training_times.append(training_time)\n",
        "        \n",
        "        # Predict on validation set\n",
        "        y_pred = catboost_model.predict(X_val_fold)\n",
        "        \n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_val_fold, y_pred)\n",
        "        precision = precision_score(y_val_fold, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_val_fold, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_val_fold, y_pred, zero_division=0)\n",
        "        \n",
        "        accuracies.append(accuracy)\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    # Calculate and print average metrics\n",
        "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
        "    avg_precision = sum(precisions) / len(precisions)\n",
        "    avg_recall = sum(recalls) / len(recalls)\n",
        "    avg_f1_score = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "    # Calculate average training time\n",
        "    avg_training_time = sum(training_times) / len(training_times)\n",
        "    print(\"For max_depth :\", max_depth)\n",
        "    print(\"Average Accuracy:\", avg_accuracy)\n",
        "    print(\"Average F1 Score:\", avg_f1_score)\n",
        "    print(\"Average Precision:\", avg_precision)\n",
        "    print(\"Average Recall:\", avg_recall)\n",
        "    print(\"Average Training Time (seconds):\", avg_training_time)\n",
        "    print('-----------------------------------------------------')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Trying Different combinations of max_depth & n_estimators**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best F1 Score: 0.5559499082900619\n",
            "Corresponding Accuracy: 0.793103448275862\n",
            "Corresponding n_estimators: 100\n",
            "Corresponding max_depth: 6\n"
          ]
        }
      ],
      "source": [
        "n_estimators_list = [50, 100, 200, 300, 500, 800, 1000]\n",
        "max_depth_list = [2, 4, 6, 8, 10, 12, 14, 16]\n",
        "\n",
        "max_f1_score = 0\n",
        "best_accuracy = 0\n",
        "best_lr = None\n",
        "best_class_weight = None\n",
        "\n",
        "for n_estimators in n_estimators_list:\n",
        "    for max_depth in max_depth_list:\n",
        "        # Define CatBoost parameters\n",
        "        params = {\n",
        "            'learning_rate': 0.1,               # Learning Rate\n",
        "            'n_estimators': n_estimators,                # Number of Trees\n",
        "            'max_depth': max_depth,                     # Depth of Trees\n",
        "            'l2_leaf_reg': 3,                   # Regularization Parameter: L2 regularization\n",
        "            'min_child_samples': 5,             # Regularization Parameter: Minimum number of samples required to split a node\n",
        "            'subsample': 0.8,                   # Subsampling\n",
        "            'loss_function': 'Logloss',         # Objective Function\n",
        "            'eval_metric': 'Accuracy',                # Evaluation Metric\n",
        "            'border_count': 128,                 # Gradient Estimation\n",
        "            'class_weights': [1,10]  # Adjust class weights because of unbalanced classes\n",
        "        }\n",
        "        # Initialize CatBoost classifier\n",
        "        catboost_model = CatBoostClassifier(**params)\n",
        "\n",
        "        # Train the model using KFold cross-validation\n",
        "        accuracies = []\n",
        "        precisions = []\n",
        "        recalls = []\n",
        "        f1_scores = []\n",
        "        training_times = []\n",
        "\n",
        "        for train_index, val_index in k_fold.split(x_train):\n",
        "            X_train_fold, X_val_fold = x_train.iloc[train_index], x_train.iloc[val_index]\n",
        "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "            \n",
        "            # Record start time\n",
        "            start_time = time.time()\n",
        "            \n",
        "            # Fit the model\n",
        "            catboost_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False)\n",
        "            \n",
        "            # Record end time\n",
        "            end_time = time.time()\n",
        "            \n",
        "            # Calculate training time\n",
        "            training_time = end_time - start_time\n",
        "            training_times.append(training_time)\n",
        "            \n",
        "            # Predict on validation set\n",
        "            y_pred = catboost_model.predict(X_val_fold)\n",
        "            \n",
        "            # Calculate metrics\n",
        "            accuracy = accuracy_score(y_val_fold, y_pred)\n",
        "            precision = precision_score(y_val_fold, y_pred, zero_division=0)\n",
        "            recall = recall_score(y_val_fold, y_pred, zero_division=0)\n",
        "            f1 = f1_score(y_val_fold, y_pred, zero_division=0)\n",
        "            \n",
        "            accuracies.append(accuracy)\n",
        "            precisions.append(precision)\n",
        "            recalls.append(recall)\n",
        "            f1_scores.append(f1)\n",
        "\n",
        "        # Calculate and print average metrics\n",
        "        avg_accuracy = sum(accuracies) / len(accuracies)\n",
        "        avg_precision = sum(precisions) / len(precisions)\n",
        "        avg_recall = sum(recalls) / len(recalls)\n",
        "        avg_f1_score = sum(f1_scores) / len(f1_scores)\n",
        "        \n",
        "        if avg_f1_score > max_f1_score:\n",
        "            max_f1_score = avg_f1_score\n",
        "            best_accuracy = avg_accuracy\n",
        "            best_n_estimators = n_estimators\n",
        "            best_max_depth = max_depth\n",
        "\n",
        "# Print the results for the best F1 score\n",
        "print(\"Best F1 Score:\", max_f1_score)\n",
        "print(\"Corresponding Accuracy:\", best_accuracy)\n",
        "print(\"Corresponding n_estimators:\", best_n_estimators)\n",
        "print(\"Corresponding max_depth:\", best_max_depth)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Trying different L2 regularization strength**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For l2_leaf_reg : 0.01\n",
            "Average Accuracy: 0.7511494252873564\n",
            "Average F1 Score: 0.42374156108171457\n",
            "Average Precision: 0.3610109335109335\n",
            "Average Recall: 0.7150000000000001\n",
            "-----------------------------------------------------\n",
            "For l2_leaf_reg : 0.1\n",
            "Average Accuracy: 0.7951724137931035\n",
            "Average F1 Score: 0.5116136889538424\n",
            "Average Precision: 0.44347485847485846\n",
            "Average Recall: 0.7683333333333333\n",
            "-----------------------------------------------------\n",
            "For l2_leaf_reg : 0.5\n",
            "Average Accuracy: 0.7562068965517241\n",
            "Average F1 Score: 0.47238291972307317\n",
            "Average Precision: 0.38477992595639654\n",
            "Average Recall: 0.7983333333333333\n",
            "-----------------------------------------------------\n",
            "For l2_leaf_reg : 1\n",
            "Average Accuracy: 0.741609195402299\n",
            "Average F1 Score: 0.5009704141000413\n",
            "Average Precision: 0.3938843101343101\n",
            "Average Recall: 0.8566666666666667\n",
            "-----------------------------------------------------\n",
            "For l2_leaf_reg : 3\n",
            "Average Accuracy: 0.793103448275862\n",
            "Average F1 Score: 0.5559499082900619\n",
            "Average Precision: 0.4786538461538462\n",
            "Average Recall: 0.8633333333333333\n",
            "-----------------------------------------------------\n",
            "For l2_leaf_reg : 5\n",
            "Average Accuracy: 0.7113793103448276\n",
            "Average F1 Score: 0.4341859850787701\n",
            "Average Precision: 0.3366892911010558\n",
            "Average Recall: 0.8300000000000001\n",
            "-----------------------------------------------------\n",
            "For l2_leaf_reg : 10\n",
            "Average Accuracy: 0.7045977011494253\n",
            "Average F1 Score: 0.4524691974691975\n",
            "Average Precision: 0.35337789661319075\n",
            "Average Recall: 0.8433333333333334\n",
            "-----------------------------------------------------\n",
            "For l2_leaf_reg : 20\n",
            "Average Accuracy: 0.7628735632183907\n",
            "Average F1 Score: 0.503991563991564\n",
            "Average Precision: 0.37939825052828147\n",
            "Average Recall: 0.8633333333333333\n",
            "-----------------------------------------------------\n",
            "For l2_leaf_reg : 40\n",
            "Average Accuracy: 0.6681609195402298\n",
            "Average F1 Score: 0.42935911914172775\n",
            "Average Precision: 0.29380154932786506\n",
            "Average Recall: 0.9166666666666667\n",
            "-----------------------------------------------------\n",
            "For l2_leaf_reg : 80\n",
            "Average Accuracy: 0.6945977011494253\n",
            "Average F1 Score: 0.4307892590501286\n",
            "Average Precision: 0.2959126984126984\n",
            "Average Recall: 0.8833333333333332\n",
            "-----------------------------------------------------\n",
            "For l2_leaf_reg : 100\n",
            "Average Accuracy: 0.6641379310344827\n",
            "Average F1 Score: 0.4049087996402575\n",
            "Average Precision: 0.2771630003982945\n",
            "Average Recall: 0.8833333333333332\n",
            "-----------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "l2_leaf_reg_list = [0.01, 0.1, 0.5, 1, 3, 5, 10, 20, 40, 80, 100]\n",
        "for l2_leaf_reg in l2_leaf_reg_list:\n",
        "    # Define CatBoost parameters\n",
        "    params = {\n",
        "        'learning_rate': 0.1,               # Learning Rate\n",
        "        'n_estimators': 100,                # Number of Trees\n",
        "        'max_depth': 6,                     # Depth of Trees\n",
        "        'l2_leaf_reg': l2_leaf_reg,                   # Regularization Parameter: L2 regularization\n",
        "        'min_child_samples': 5,             # Regularization Parameter: Minimum number of samples required to split a node\n",
        "        'subsample': 0.8,                   # Subsampling\n",
        "        'loss_function': 'Logloss',         # Objective Function\n",
        "        'eval_metric': 'Accuracy',                # Evaluation Metric\n",
        "        'border_count': 128,                 # Gradient Estimation\n",
        "        'class_weights': [1, 10]  # Adjust class weights because of unbalanced classes\n",
        "    }\n",
        "\n",
        "    # Initialize CatBoost classifier\n",
        "    catboost_model = CatBoostClassifier(**params)\n",
        "\n",
        "    # Train the model using KFold cross-validation\n",
        "    accuracies = []\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1_scores = []\n",
        "    training_times = []\n",
        "\n",
        "    for train_index, val_index in k_fold.split(x_train):\n",
        "        X_train_fold, X_val_fold = x_train.iloc[train_index], x_train.iloc[val_index]\n",
        "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "        \n",
        "        # Record start time\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Fit the model\n",
        "        catboost_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False)\n",
        "        \n",
        "        # Record end time\n",
        "        end_time = time.time()\n",
        "        \n",
        "        # Calculate training time\n",
        "        training_time = end_time - start_time\n",
        "        training_times.append(training_time)\n",
        "        \n",
        "        # Predict on validation set\n",
        "        y_pred = catboost_model.predict(X_val_fold)\n",
        "        \n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_val_fold, y_pred)\n",
        "        precision = precision_score(y_val_fold, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_val_fold, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_val_fold, y_pred, zero_division=0)\n",
        "        \n",
        "        accuracies.append(accuracy)\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    # Calculate and print average metrics\n",
        "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
        "    avg_precision = sum(precisions) / len(precisions)\n",
        "    avg_recall = sum(recalls) / len(recalls)\n",
        "    avg_f1_score = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "    # Calculate average training time\n",
        "    avg_training_time = sum(training_times) / len(training_times)\n",
        "    print(\"For l2_leaf_reg :\", l2_leaf_reg)\n",
        "    print(\"Average Accuracy:\", avg_accuracy)\n",
        "    print(\"Average F1 Score:\", avg_f1_score)\n",
        "    print(\"Average Precision:\", avg_precision)\n",
        "    print(\"Average Recall:\", avg_recall)\n",
        "    print('-----------------------------------------------------')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Trying different subsample**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For subsample : 0.1\n",
            "Average Accuracy: 0.8505747126436782\n",
            "Average F1 Score: 0.5873353839143313\n",
            "Average Precision: 0.48629148629148633\n",
            "Average Recall: 0.8016666666666665\n",
            "-----------------------------------------------------\n",
            "For subsample : 0.2\n",
            "Average Accuracy: 0.7612643678160922\n",
            "Average F1 Score: 0.4999131862289756\n",
            "Average Precision: 0.39441558441558444\n",
            "Average Recall: 0.8708333333333332\n",
            "-----------------------------------------------------\n",
            "For subsample : 0.5\n",
            "Average Accuracy: 0.6479310344827587\n",
            "Average F1 Score: 0.4174655861928711\n",
            "Average Precision: 0.31214390142021725\n",
            "Average Recall: 0.8716666666666665\n",
            "-----------------------------------------------------\n",
            "For subsample : 0.6\n",
            "Average Accuracy: 0.7688505747126438\n",
            "Average F1 Score: 0.4500663423264043\n",
            "Average Precision: 0.3859586247086247\n",
            "Average Recall: 0.7183333333333334\n",
            "-----------------------------------------------------\n",
            "For subsample : 0.8\n",
            "Average Accuracy: 0.793103448275862\n",
            "Average F1 Score: 0.5559499082900619\n",
            "Average Precision: 0.4786538461538462\n",
            "Average Recall: 0.8633333333333333\n",
            "-----------------------------------------------------\n",
            "For subsample : 1\n",
            "Average Accuracy: 0.7688505747126436\n",
            "Average F1 Score: 0.5028411938938255\n",
            "Average Precision: 0.39885620915032677\n",
            "Average Recall: 0.8008333333333333\n",
            "-----------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "subsample_list = [0.1, 0.2, 0.5, 0.6, 0.8, 1]\n",
        "for subsample in subsample_list:\n",
        "    # Define CatBoost parameters\n",
        "    params = {\n",
        "        'learning_rate': 0.1,               # Learning Rate\n",
        "        'n_estimators': 100,                # Number of Trees\n",
        "        'max_depth': 6,                     # Depth of Trees\n",
        "        'l2_leaf_reg': 3,                   # Regularization Parameter: L2 regularization\n",
        "        'min_child_samples': 5,             # Regularization Parameter: Minimum number of samples required to split a node\n",
        "        'subsample': subsample,                   # Subsampling\n",
        "        'loss_function': 'Logloss',         # Objective Function\n",
        "        'eval_metric': 'Accuracy',                # Evaluation Metric\n",
        "        'border_count': 128,                 # Gradient Estimation\n",
        "        'class_weights': [1, 10]  # Adjust class weights because of unbalanced classes\n",
        "    }\n",
        "\n",
        "    # Initialize CatBoost classifier\n",
        "    catboost_model = CatBoostClassifier(**params)\n",
        "\n",
        "    # Train the model using KFold cross-validation\n",
        "    accuracies = []\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1_scores = []\n",
        "    training_times = []\n",
        "\n",
        "    for train_index, val_index in k_fold.split(x_train):\n",
        "        X_train_fold, X_val_fold = x_train.iloc[train_index], x_train.iloc[val_index]\n",
        "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "        \n",
        "        # Record start time\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Fit the model\n",
        "        catboost_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False)\n",
        "        \n",
        "        # Record end time\n",
        "        end_time = time.time()\n",
        "        \n",
        "        # Calculate training time\n",
        "        training_time = end_time - start_time\n",
        "        training_times.append(training_time)\n",
        "        \n",
        "        # Predict on validation set\n",
        "        y_pred = catboost_model.predict(X_val_fold)\n",
        "        \n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_val_fold, y_pred)\n",
        "        precision = precision_score(y_val_fold, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_val_fold, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_val_fold, y_pred, zero_division=0)\n",
        "        \n",
        "        accuracies.append(accuracy)\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    # Calculate and print average metrics\n",
        "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
        "    avg_precision = sum(precisions) / len(precisions)\n",
        "    avg_recall = sum(recalls) / len(recalls)\n",
        "    avg_f1_score = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "    # Calculate average training time\n",
        "    avg_training_time = sum(training_times) / len(training_times)\n",
        "    print(\"For subsample :\", subsample)\n",
        "    print(\"Average Accuracy:\", avg_accuracy)\n",
        "    print(\"Average F1 Score:\", avg_f1_score)\n",
        "    print(\"Average Precision:\", avg_precision)\n",
        "    print(\"Average Recall:\", avg_recall)\n",
        "    print('-----------------------------------------------------')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Trying different min_child_samples**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For min_child_samples : 1\n",
            "Average Accuracy: 0.793103448275862\n",
            "Average F1 Score: 0.5559499082900619\n",
            "Average Precision: 0.4786538461538462\n",
            "Average Recall: 0.8633333333333333\n",
            "-----------------------------------------------------\n",
            "For min_child_samples : 5\n",
            "Average Accuracy: 0.793103448275862\n",
            "Average F1 Score: 0.5559499082900619\n",
            "Average Precision: 0.4786538461538462\n",
            "Average Recall: 0.8633333333333333\n",
            "-----------------------------------------------------\n",
            "For min_child_samples : 10\n",
            "Average Accuracy: 0.793103448275862\n",
            "Average F1 Score: 0.5559499082900619\n",
            "Average Precision: 0.4786538461538462\n",
            "Average Recall: 0.8633333333333333\n",
            "-----------------------------------------------------\n",
            "For min_child_samples : 20\n",
            "Average Accuracy: 0.793103448275862\n",
            "Average F1 Score: 0.5559499082900619\n",
            "Average Precision: 0.4786538461538462\n",
            "Average Recall: 0.8633333333333333\n",
            "-----------------------------------------------------\n",
            "For min_child_samples : 50\n",
            "Average Accuracy: 0.793103448275862\n",
            "Average F1 Score: 0.5559499082900619\n",
            "Average Precision: 0.4786538461538462\n",
            "Average Recall: 0.8633333333333333\n",
            "-----------------------------------------------------\n",
            "For min_child_samples : 100\n",
            "Average Accuracy: 0.793103448275862\n",
            "Average F1 Score: 0.5559499082900619\n",
            "Average Precision: 0.4786538461538462\n",
            "Average Recall: 0.8633333333333333\n",
            "-----------------------------------------------------\n",
            "For min_child_samples : 200\n",
            "Average Accuracy: 0.793103448275862\n",
            "Average F1 Score: 0.5559499082900619\n",
            "Average Precision: 0.4786538461538462\n",
            "Average Recall: 0.8633333333333333\n",
            "-----------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "min_child_samples_list = [1, 5, 10, 20, 50, 100, 200]\n",
        "for min_child_samples in min_child_samples_list:\n",
        "    # Define CatBoost parameters\n",
        "    params = {\n",
        "        'learning_rate': 0.1,               # Learning Rate\n",
        "        'n_estimators': 100,                # Number of Trees\n",
        "        'max_depth': 6,                     # Depth of Trees\n",
        "        'l2_leaf_reg': 3,                   # Regularization Parameter: L2 regularization\n",
        "        'min_child_samples': min_child_samples,             # Regularization Parameter: Minimum number of samples required to split a node\n",
        "        'subsample': 0.8,                   # Subsampling\n",
        "        'loss_function': 'Logloss',         # Objective Function\n",
        "        'eval_metric': 'Accuracy',                # Evaluation Metric\n",
        "        'border_count': 128,                 # Gradient Estimation\n",
        "        'class_weights': [1, 10]  # Adjust class weights because of unbalanced classes\n",
        "    }\n",
        "\n",
        "    # Initialize CatBoost classifier\n",
        "    catboost_model = CatBoostClassifier(**params)\n",
        "\n",
        "    # Train the model using KFold cross-validation\n",
        "    accuracies = []\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1_scores = []\n",
        "    training_times = []\n",
        "\n",
        "    for train_index, val_index in k_fold.split(x_train):\n",
        "        X_train_fold, X_val_fold = x_train.iloc[train_index], x_train.iloc[val_index]\n",
        "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "        \n",
        "        # Record start time\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Fit the model\n",
        "        catboost_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), verbose=False)\n",
        "        \n",
        "        # Record end time\n",
        "        end_time = time.time()\n",
        "        \n",
        "        # Calculate training time\n",
        "        training_time = end_time - start_time\n",
        "        training_times.append(training_time)\n",
        "        \n",
        "        # Predict on validation set\n",
        "        y_pred = catboost_model.predict(X_val_fold)\n",
        "        \n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_val_fold, y_pred)\n",
        "        precision = precision_score(y_val_fold, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_val_fold, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_val_fold, y_pred, zero_division=0)\n",
        "        \n",
        "        accuracies.append(accuracy)\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    # Calculate and print average metrics\n",
        "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
        "    avg_precision = sum(precisions) / len(precisions)\n",
        "    avg_recall = sum(recalls) / len(recalls)\n",
        "    avg_f1_score = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "    # Calculate average training time\n",
        "    avg_training_time = sum(training_times) / len(training_times)\n",
        "    print(\"For min_child_samples :\", min_child_samples)\n",
        "    print(\"Average Accuracy:\", avg_accuracy)\n",
        "    print(\"Average F1 Score:\", avg_f1_score)\n",
        "    print(\"Average Precision:\", avg_precision)\n",
        "    print(\"Average Recall:\", avg_recall)\n",
        "    print('-----------------------------------------------------')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
